# =======================================================================
# NEO4J
# Conexión al servidor Neo4j corriendo en el contenedor Docker 'neo4j_graph'
# Los puertos y credenciales coinciden con el archivo docker-compose.yml
# =======================================================================
NEO4J_URI=la_url_al_correr_neo4j_desde_docker
NEO4J_USER=usuario
NEO4J_PASSWORD=contraseña


# =======================================================================
# OPENAI
# Clave API para la generación de respuesta (GPT-4)
# =======================================================================
OPENAI_API_KEY=la_de_erik

# =======================================================================
# OPCIONAL: Para usar modelos LLM locales (si usas src/generation/local_rag.py)
# Descomenta y ajusta si usas LM Studio u otro servidor compatible con OpenAI API.
# =======================================================================
# LOCAL_LLM_URL=http://localhost:1234/v1
# LOCAL_LLM_API_KEY=lm-studio
